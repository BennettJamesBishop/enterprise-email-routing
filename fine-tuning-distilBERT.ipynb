{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import various Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bennettbishop/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopw = stopwords.words('english')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request</th>\n",
       "      <th>category</th>\n",
       "      <th>stratify_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m looking for some information regarding pay...</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR__payroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’m looking for some information regarding lea...</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR__leave policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m looking for some information regarding emp...</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR__employee handbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m looking for some information regarding job...</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR__job application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m looking for some information regarding ben...</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR__benefits enrollment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             request category  \\\n",
       "0  I’m looking for some information regarding pay...       HR   \n",
       "1  I’m looking for some information regarding lea...       HR   \n",
       "2  I’m looking for some information regarding emp...       HR   \n",
       "3  I’m looking for some information regarding job...       HR   \n",
       "4  I’m looking for some information regarding ben...       HR   \n",
       "\n",
       "              stratify_col  \n",
       "0              HR__payroll  \n",
       "1         HR__leave policy  \n",
       "2    HR__employee handbook  \n",
       "3      HR__job application  \n",
       "4  HR__benefits enrollment  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = 'data/full_dataset.csv'\n",
    "df = pd.read_csv(root_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train, Validation, Test using Stratified_Col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique categories: 5\n",
      "Encoded labels: [2 1 3 4 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode the 'category' column into numerical labels\n",
    "df['encoded_text'] = df['category'].astype('category').cat.codes\n",
    "print(f\"Unique categories: {df['category'].nunique()}\")\n",
    "print(f\"Encoded labels: {df['encoded_text'].unique()}\")\n",
    "\n",
    "# Separate columns for splitting\n",
    "data_texts = df['request'].to_list()  # 'request' is the text data\n",
    "data_labels = df['encoded_text'].to_list()  # Encoded class labels\n",
    "stratify_values = df['stratify_col'].to_list()  # Stratification column\n",
    "\n",
    "# Split the data into Train/Validation sets with stratification\n",
    "train_texts, val_texts, train_labels, val_labels, train_stratify, val_stratify = train_test_split(\n",
    "    data_texts, data_labels, stratify_values, \n",
    "    test_size=0.2, stratify=stratify_values, random_state=0\n",
    ")\n",
    "\n",
    "# Split the Train set further into Train/Test with stratification\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    train_texts, train_labels, \n",
    "    test_size=0.1, stratify=train_stratify, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Save test/train/val to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits saved as train.csv, validation.csv, and test.csv\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames for each split\n",
    "train_df = pd.DataFrame({\n",
    "    'request': train_texts,\n",
    "    'label': train_labels\n",
    "})\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    'request': val_texts,\n",
    "    'label': val_labels\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'request': test_texts,\n",
    "    'label': test_labels\n",
    "})\n",
    "\n",
    "# Save DataFrames to CSV files\n",
    "train_df.to_csv(\"data/train.csv\", index=False)\n",
    "val_df.to_csv(\"data/validation.csv\", index=False)\n",
    "test_df.to_csv(\"data/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Out Split Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Mapping (Encoded -> Category):\n",
      "0: Facilities Management\n",
      "1: Finance\n",
      "2: HR\n",
      "3: IT Support\n",
      "4: Marketing\n",
      "Train set size after second split: 3596\n",
      "Test set size: 400\n",
      "Example train_texts: Do you have the latest version of the diversity and inclusion policies handbook? I need it for a new hire orientation.\n",
      "Example train_labels: 2\n",
      "Example val_texts: Need access to server maintenance.\n",
      "Example val_labels: 3\n",
      "Example test_texts: Could you review and approve the budget variance analysis for this month? Let me know if there’s anything I need to address.\n",
      "Example test_labels: 1\n",
      "\n",
      "Final dataset information:\n",
      "Train set size: 3596\n",
      "Validation set size: 1000\n",
      "Test set size: 400\n"
     ]
    }
   ],
   "source": [
    "# Map numerical labels back to category names\n",
    "label_mapping = dict(enumerate(df['category'].astype('category').cat.categories))\n",
    "print(\"\\nLabel Mapping (Encoded -> Category):\")\n",
    "for encoded, category in label_mapping.items():\n",
    "    print(f\"{encoded}: {category}\")\n",
    "\n",
    "\n",
    "print(f\"Train set size after second split: {len(train_texts)}\")\n",
    "print(f\"Test set size: {len(test_texts)}\")\n",
    "print(f\"Example train_texts: {train_texts[1]}\") \n",
    "print(f\"Example train_labels: {train_labels[1]}\")\n",
    "print(f\"Example val_texts: {val_texts[1]}\") \n",
    "print(f\"Example val_labels: {val_labels[1]}\")\n",
    "print(f\"Example test_texts: {test_texts[1]}\") \n",
    "print(f\"Example test_labels: {test_labels[1]}\")\n",
    "\n",
    "# Output dataset information\n",
    "print(\"\\nFinal dataset information:\")\n",
    "print(f\"Train set size: {len(train_texts)}\")\n",
    "print(f\"Validation set size: {len(val_texts)}\")\n",
    "print(f\"Test set size: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/enterprise-email-routing/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'count'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m sns\u001b[38;5;241m.\u001b[39mdisplot(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe num of words \u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m~/enterprise-email-routing/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/enterprise-email-routing/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'count'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
