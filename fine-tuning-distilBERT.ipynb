{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune DistilBERT For Multi-Class Text Classification Using Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we explore the capabilities of DistilBERT for multi-class text classification by comparing three approaches: no fine-tuning, standard fine-tuning, and LoRA fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents:\n",
    "    1. Data Pre-Processing\n",
    "    2. Metrics We Will Measure\n",
    "    3. Classification with No Fine-Tuning\n",
    "    4. Classification with Standard Fine-Tuning\n",
    "    5. Classification with LoRA Fine-Tuning\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bennettbishop/enterprise-email-routing/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Import required packages\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import tf_keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Split into Train, Validation, Test using Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "root_path = 'data/full_dataset.csv'\n",
    "df = pd.read_csv(root_path)\n",
    "df.head()\n",
    "\n",
    "# Encode the 'category' column into numerical labels\n",
    "df['encoded_text'] = df['category'].astype('category').cat.codes\n",
    "\n",
    "# Separate columns for splitting\n",
    "data_texts = df['request'].to_list()  # 'request' is the text data\n",
    "data_labels = df['encoded_text'].to_list()  # Encoded class labels\n",
    "stratify_values = df['stratify_col'].to_list()  # Stratification column\n",
    "\n",
    "# Split the data into Train/Validation sets with stratification\n",
    "train_texts, val_texts, train_labels, val_labels, train_stratify, val_stratify = train_test_split(\n",
    "    data_texts, data_labels, stratify_values, \n",
    "    test_size=0.2, stratify=stratify_values, random_state=0\n",
    ")\n",
    "\n",
    "# Split the Train set further into Train/Test with stratification\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    train_texts, train_labels, \n",
    "    test_size=0.1, stratify=train_stratify, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. View test/train/validation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Mapping (Encoded -> Category):\n",
      "0: Facilities Management\n",
      "1: Finance\n",
      "2: HR\n",
      "3: IT Support\n",
      "4: Marketing\n",
      "\n",
      "Final dataset information:\n",
      "Train set size: 3596\n",
      "Validation set size: 1000\n",
      "Test set size: 400\n",
      "Example train_texts: ['I’m gathering details about rewards for long-term employees and was hoping you could provide some insight. Let me know if you need further specifics from me.', 'Do you have the latest version of the diversity and inclusion policies handbook? I need it for a new hire orientation.', 'Could you share detailed insights on the performance metrics for keyword research for PPC campaigns? I’d like to use this data for our planning.']\n",
      "Example train_labels: [2, 2, 4]\n",
      "Example val_texts: ['Could you outline the steps to optimize our launching retargeting ads approach? Any case studies or examples would be helpful.', 'Need access to server maintenance.', 'Insights on customer retention strategies performance needed.']\n",
      "Example val_labels: [4, 3, 4]\n",
      "Example test_texts: ['I’m experiencing an issue with software installation. Can you assist in diagnosing and resolving the problem as soon as possible?', 'Could you review and approve the budget variance analysis for this month? Let me know if there’s anything I need to address.', 'I wanted to check on the status of my request for access to storage capacity planning. Let me know if further details are needed.']\n",
      "Example test_labels: [3, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "# Map numerical labels back to category names\n",
    "label_mapping = dict(enumerate(df['category'].astype('category').cat.categories))\n",
    "print(\"\\nLabel Mapping (Encoded -> Category):\")\n",
    "\n",
    "for encoded, category in label_mapping.items():\n",
    "    print(f\"{encoded}: {category}\")\n",
    "\n",
    "# Output dataset information\n",
    "print(\"\\nFinal dataset information:\")\n",
    "print(f\"Train set size: {len(train_texts)}\")\n",
    "print(f\"Validation set size: {len(val_texts)}\")\n",
    "print(f\"Test set size: {len(test_texts)}\")\n",
    "\n",
    "print(f\"Example train_texts: {train_texts[:3]}\") \n",
    "print(f\"Example train_labels: {train_labels[:3]}\")\n",
    "print(f\"Example val_texts: {val_texts[:3]}\") \n",
    "print(f\"Example val_labels: {val_labels[:3]}\")\n",
    "print(f\"Example test_texts: {test_texts[:3]}\") \n",
    "print(f\"Example test_labels: {test_labels[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Optional: Save test/train/val to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for each split\n",
    "train_df = pd.DataFrame({\n",
    "    'request': train_texts,\n",
    "    'label': train_labels\n",
    "})\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    'request': val_texts,\n",
    "    'label': val_labels\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'request': test_texts,\n",
    "    'label': test_labels\n",
    "})\n",
    "\n",
    "# Save DataFrames to CSV files\n",
    "train_df.to_csv(\"data/train.csv\", index=False)\n",
    "val_df.to_csv(\"data/validation.csv\", index=False)\n",
    "test_df.to_csv(\"data/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Tokenize Data For DistilBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation = True, padding = True  )\n",
    "\n",
    "val_encodings = tokenizer(val_texts, truncation = True, padding = True )\n",
    "\n",
    "test_encodings = tokenizer(test_texts, truncation = True, padding = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 37), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 37), dtype=tf.int32, name=None)}, TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).batch(32)\n",
    "\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).batch(32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    ")).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metrics to Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predict Categories Without Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=5)\n",
    "opt = tf_keras.optimizers.legacy.Adam(learning_rate=5e-5)\n",
    "loss = tf_keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Raw logits expected\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Evaluate Performance of DistilBERT with no fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Accuracy: 0.16\n",
      "Precision: 0.16400330757965964\n",
      "Recall: 0.16\n",
      "F1 Score: 0.1155358770903418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 12:34:38.873624: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "/Users/bennettbishop/enterprise-email-routing/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Perform prediction on the test dataset\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Iterate over test dataset to collect true labels and predictions\n",
    "for batch in test_dataset:\n",
    "    input_data, labels = batch\n",
    "    y_true.extend(labels.numpy())  # Collect true labels\n",
    "    logits = model.predict(input_data).logits  # Predict logits\n",
    "    predictions = logits.argmax(axis=-1)  # Convert logits to predicted labels\n",
    "    y_pred.extend(predictions)\n",
    "\n",
    "# Evaluate the model\n",
    "no_finetuning_accuracy, no_finetuning_precision, no_finetuning_recall, no_finetuning_f1 = evaluate_model(y_true, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {no_finetuning_accuracy}\")\n",
    "print(f\"Precision: {no_finetuning_precision}\")\n",
    "print(f\"Recall: {no_finetuning_recall}\")\n",
    "print(f\"F1 Score: {no_finetuning_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict Categories With Standard Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "113/113 [==============================] - 99s 855ms/step - loss: 0.3511 - accuracy: 0.9274 - val_loss: 0.0446 - val_accuracy: 0.9890\n",
      "Epoch 2/3\n",
      "113/113 [==============================] - 96s 852ms/step - loss: 0.0208 - accuracy: 0.9972 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "113/113 [==============================] - 106s 941ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=5)\n",
    "opt = tf_keras.optimizers.legacy.Adam(learning_rate=5e-5)\n",
    "loss = tf_keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Raw logits expected\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=3,\n",
    "    verbose=1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 691ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 1s 770ms/step\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Overlap: 0\n",
      "Train-Val Overlap: 0\n",
      "Val-Test Overlap: 0\n"
     ]
    }
   ],
   "source": [
    "train_set = set(train_texts)\n",
    "val_set = set(val_texts)\n",
    "test_set = set(test_texts)\n",
    "\n",
    "print(f\"Train-Test Overlap: {len(train_set & test_set)}\")\n",
    "print(f\"Train-Val Overlap: {len(train_set & val_set)}\")\n",
    "print(f\"Val-Test Overlap: {len(val_set & test_set)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_models/tokenizer_config.json',\n",
       " './saved_models/special_tokens_map.json',\n",
       " './saved_models/vocab.txt',\n",
       " './saved_models/added_tokens.json')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory = \"./saved_models\" \n",
    "\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
